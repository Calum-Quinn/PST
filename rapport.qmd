---
title: "Rapport"
author: "Calum Quinn"
format: html
editor: visual
---

# TP 1

## Introduction

L’objectif de ce travail pratique consiste à se familiariser avec les commandes de base du logiciel R, à utiliser les techniques d’analyse pour une variable statistique puis deux et finalement à apprendre à rédiger des rapports d’analyse de données.

------------------------------------------------------------------------

## Exercice 1

### b) Charger les données dans R en utilisant les fonctions scan() et read.table().

#### cpus.txt

```{r}
cpus <- scan("Data/cpus.txt")
```

#### examen.txt

```{r}
examen <- read.table("Data/examen.txt",TRUE)
```

------------------------------------------------------------------------

### c) Pour voir le contenu de l’objet cpus

```{r}
cpus
```

------------------------------------------------------------------------

### d) Pour accéder à la 19ème composante du vecteur cpus

```{r}
cpus[19]
```

------------------------------------------------------------------------

### e) Pour obtenir une partie du vecteur cpus comme par exemple les éléments du vecteur compris entre la 5ème et la 21ème composante

```{r}
cpus[5:21]
```

------------------------------------------------------------------------

### f) Pour extraire du vecteur cpus ses éléments supérieurs à 200

```{r}
cpus[cpus > 200]
```

------------------------------------------------------------------------

### g) Il est possible d’accéder directement aux composantes d’une table par le nom. Par exemple, si on veut afficher la composante note de l’objet examen

```{r}
examen$note
```

------------------------------------------------------------------------

### h) On peut aussi accéder en profondeur aux composantes

```{r}
examen$note[9]
```

------------------------------------------------------------------------

### i) La méthode la plus simple pour créer un vecteur consiste à énumérer ses éléments à l’aide de la fonction c()

```{r}
mesdonnees <- c(2.9, 3.4, 3.4, 3.7, 3.7, 2.8, 2.1, 2.5, 2.6, 1.5)
```

```{r}
couleurs <- c("bleu", "vert", "blanc", "noir", "jaune")
```

------------------------------------------------------------------------

### j) On peut ôter des composantes d’un vecteur en indiquant entre crochets les indices précédés du signe négatif

```{r}
mesdonnees[-c(5:9)]
```

------------------------------------------------------------------------

### k) Finalement, le contenu de votre environnement de travail est affiché

```{r}
ls()
```

------------------------------------------------------------------------

## Exercice 2

### a) Construire un diagramme branche-et-feuilles, une boîte à moustaches et un histogramme des données observées à l’aide des commandes ci-dessous.

```{r}
stem(cpus)

par(mfrow=c(1,2), pty="s")
boxplot(cpus, xlab="performance relative", col="darkslategray4", horizontal=T)
rug(cpus)
hist(cpus, xlab="performance relative", ylab="fréquence", main="",
  col="darkslategray4")
par(mfrow=c(1,1))
```

1.  *Quels sont les effets de cette commande?*

```{r}
boxplot(cpus, xlab="performance relative", col="darkslategray4", horizontal=T)
```

Cette commande à pour effet de générer un boxplot horizontal des données avec comme légende de l'axe x `performance relative` et avec la couleur du graphique en gris.

2.  *Quel est l'effet de la fonction `rug()?`*

Cette commande ajoute des graduations à l'axe horizontal pour représenter la densité des valeurs (diagramme en aiguilles).

------------------------------------------------------------------------

### b) Commenter la distribution des valeurs observées en se basant sur les graphiques de la Figure 5 : valeur(s) atypique(s), asymétrie

Comme on peut le voir dans les deux graphiques, la majorité des valeurs se trouvent au début de l'échelle donnée (\~0-100). Ceci nous amène à dire qu'il y a une asymétrie positive et qu'il y a des valeurs atypiques entre environ 200 et 900.

------------------------------------------------------------------------

### c) Calculer la performance relative médiane et la performance relative moyenne des valeurs observées en utilisant les fonctions de R adéquates. Est-il plus approprié d’utiliser la médiane ou la moyenne ?

```{r}
median(cpus)

mean(cpus)
```

En sachant que la grande majorité des valeurs se trouvent entre 0 et 100, la moyenne et la médiane sont assez écarté. Ceci vient très problement des valeurs atypiques qui tire beaucoup la moyenne vers le haut. Dans ce cas il est plus logique d'utiliser la médiane car elle est moins affectée par les quelques valeurs atypiques très grandes.

------------------------------------------------------------------------

### d) Déterminer le(s) mode(s) des valeurs observées à l’aide des commandes suivantes :

```{r}
n.cpus <- table(cpus)
as.numeric(names(n.cpus)[n.cpus==max(n.cpus)])
```

------------------------------------------------------------------------

### e) Que fait la commande suivante ?

```{r}
summary(cpus)
```

La fonction nous rend une vision globale de l'objet, dans ce cas `cpus.txt`. Il nous donne les informations:

-   Valeur minimum
-   Premier Quartile (25% des données sont plus petites que cette valeur)
-   Médiane
-   Moyenne
-   Troisième Quartile (25% des données sont plus grande que cette valeur)
-   Valeur maximum

------------------------------------------------------------------------

### f) Décrire l’effet sur la moyenne et sur la médiane des trois interventions suivantes :

1.  *Ajouter un processeur de performance relative 43*

```{r}
cpus<-c(cpus,43)
summary(cpus)
```

La médiane augmente puisque la valeur ajoutée est plus grande que la médiane précédente.

A l'inverse, la moyenne descend puisque la valeur ajoutée est plus petite.

2.  *Soustraire 9 à chaque valeur observée*

```{r}
cpus<- cpus - 9
summary(cpus)
```

On voit que soustraire 9 à chaque valeur à eu comme effet de soustraire exactement 9 à toutes les valeurs calculées (médiane, moyenne, ...).

3.  *Diviser chaque observation par 3.*

J'ai ajouté à nouveau les 9 à chaque valeur avant de faire ça pour éviter d'avoir des calculs particulier au niveau des valeurs négatives.

```{r}
cpus<- cpus + 9
cpus<- cpus / 3
summary(cpus)
```

On remarque que diviser toutes les valeurs par une constane (dans ce cas 3), divise également la médiane et la moyenne par la même constante.

------------------------------------------------------------------------

### g) Calculer l’écart-type des performances relatives une fois avec les valeurs atypiques et une fois sans en utilisant la fonction sd(). Les valeurs atypiques peuvent être déterminées à l’aide de la fonction boxplot() avec plot=FALSE comme argument. Que constate-t-on ? L’écart-type est-il un indicateur robuste ?

```{r}
ecartTypeAvec<-sd(cpus)
print(ecartTypeAvec)
```

```{r}
valeursAtypiques<-boxplot(cpus,plot = FALSE)$out
print(valeursAtypiques)
```

```{r}
ecartTypeSans <- sd(cpus[!cpus %in% valeursAtypiques])
print(ecartTypeSans)
```

L'écart-type calculé avec les valeurs atypique et largement plus grand que sans. Ceci est normal mais montre qu'il faut faire attention lors de l'utilisation de celui-ci. C'est donc un indicateur non robuste car il est fortement influencé par les valeurs extrêmes.

## Exercice 3

### a) Tracer les boîtes à moustaches en parallèle en utilisant les commandes suivantes :

```{r}
lblue<-"#528B8B"
par(pty="s")
boxplot(note~groupe, data=examen, ylim=c(1,6), xlab="groupe", varwidth=T, col=lblue, main="examen")
abline(h=4, lty=2)
```

------------------------------------------------------------------------

### b) Rajouter les bâtonnets des notes des étudiants des deux classes, sur le côté gauche des boîtes à moustaches pour la classe A (side=2 comme argument de la fonction rug()) et sur le côté droite pour la classe B (side=4 comme argument de la fonction rug()).

```{r}
par(pty="s")
boxplot(note~groupe, data=examen, ylim=c(1,6), xlab="groupe", varwidth=T, col=lblue, main="examen")
abline(h=4, lty=2)

note.A<-split(examen$note, examen$groupe)$A
note.B<-split(examen$note, examen$groupe)$B

rug(note.A, side=2)
rug(note.B, side=4)
```

------------------------------------------------------------------------

### c) En se basant sur la Figure 2, existe-t-il une différence significative entre les deux groupes à l'examen de fin d'unité ?

Pas particulièrement, les différences sont les suivantes:

-   Le groupe B à deux personnes ayant fait une note hors norme (1-2).
-   Le groupe B à une dispersion légèrement plus grande mais généralement c'est similaire au groupe A.
-   La médiane du groupe B est légèrement plus élevée.
-   Le groupe A n'a que 25% en dessous du 4, le groupe B en a plus.

------------------------------------------------------------------------

### d) Observe-t-on sur les boîtes à moustaches une différence entre les dispersions des deux groupes ?

Oui, comme cité à la question précédente le groupe B est légèrement plus dispersé.

------------------------------------------------------------------------

### e) Calculer les écarts-types des deux groupes à l’aide des fonctions by() et sd().

```{r}
ecartsTypes <- by(examen$note, examen$groupe, sd)
print(ecartsTypes)

ecartsTypes <- by(examen$note, examen$groupe, function(x) sd(x, na.rm = TRUE))
print(ecartsTypes)
```

Comme on le voit à la première tentative, le groupe B possède des valeurs nulles et donc il faut les enlever pour calculer l'écart-type.

------------------------------------------------------------------------

### f) Que peut-on déduire en comparant les conclusions établies en c., d. et e. ?

Qu'en effet le groupe B à un plus grand écart entre les résultats des étudiants. Par contre puisque la médiane est plus élevée que le groupe A, ceci montre qu'il y a probablement des différences plus significatives entre les élèves.

------------------------------------------------------------------------

### À votre avis, entre les boîtes à moustaches en parallèle et le graphique tracé ci-dessus, lequel est le plus approprié ?

Le graphique semble plus adapté car même s'il ne montre pas autant clairement les pourcentiles, il démontre plus de granularité.

Nous pouvons par exemple voir que dans les deux groupes il y a un creux dans la grande masse de valeurs, c'est donc une répartition bimodale pour les deux.

Le graphique donne une meilleure vision globale du niveau des étudiants.

------------------------------------------------------------------------

## Exercice 4

### a)

```{r}
library(ggplot2)
library(arules)
data("AdultUCI")
```

```{r}
dframe<-AdultUCI[, c("education", "hours-per-week")]
colnames(dframe)<-c("education", "hours_per_week")
str(dframe)
```

1.  *Pourquoi ce changement de nom de variable ?*

Car R peu comprendre les "-" comme des soustractions, il est donc plus sage de mettre des "\_" dans les nom de variables. Il est aussi plus commun d'utiliser les "\_" pour représenter des espaces en programmation.

*Tracer les boîtes à moustaches en parallèle de la Figure 8 dans lesquelles est représenté le temps hebdomadaire consacré au travail par les Américains recensés selon leur formation.*

```{r}
n=dim(na.omit(dframe))[1]
today<-format(Sys.time(), "%a %b %d %X %Y")

ggplot(dframe, aes(x=hours_per_week, y=education)) +
  geom_point(colour="lightblue", alpha=0.1, position="jitter") +
  geom_boxplot(outlier.size=0, alpha=0.2) +
  theme_bw(base_size=12) +
  theme(
    legend.position="none",
    plot.title=element_text(hjust=0.5, face="bold")) +
  labs(
    color="",
    fill="",
    x="hours per week",
    y="",
    title=paste("Census Income Database (n = ",n,")", sep=""),
    caption = today
    )
```

*Commenter le graphique obtenu.*

Le graphique semble séparé en deux parties, tous les niveaux d'études sauf `Doctorate` et `Prof-school` ont une médiane à 40h par semaine.

La séparation mentionné est représenté par le fait que les niveaux de `Preschool` jusqu'à `12th` ont le 3ème quartile à 40h et les autres (sauf `Some-college`) ont leur 1er quartile à la même valeur.

Il peut donc en être déduit que la majorité des personnes n'ayant pas obtenu un diplome de `high-shool` ou plus travaillent 40h ou moins par semaine. L'inverse et donc aussi vrai.

------------------------------------------------------------------------

### b) Calculer la proportion d’observations contenant des valeurs manquantes en utilisant les commandes ci-dessous.

```{r}
dim(AdultUCI)
nrows<-nrow(AdultUCI)
n.missing<-rowSums(is.na(AdultUCI))
sum(n.missing>0)/nrows
```

------------------------------------------------------------------------

### c) En se basant sur les boîtes à moustaches en parallèle de la Figure 8, pour quel type de formation observe-t-on la plus grande dispersion du temps de travail ? Existe-t-il une différence entre les médianes des types de formation ? En donner brièvement la raison.

Le type de formation présentant la plus grande dispersion semble être `11th`.

En ce qui concerne les médianes, seulement `Doctorate` et `Prof-school` sont différentes et supérieurs à 40h par semaine.

Ceux-ci sont des types de travail qui sont reconnus pour être difficile mais aussi très occupant en terme de temps de travail.

------------------------------------------------------------------------

### d) Pour chaque type de formation, on peut déterminer puis afficher à l’écran le temps maximal de travail hebdomadaire à l’aide des commandes

```{r}
nx<-by(dframe$hours_per_week, dframe$education, max, na.rm=T)
nx
```

### La formation pour laquelle un temps maximal a été observé se détermine par les commandes suivantes, est-ce surprenant?

```{r}
max(nx)
names(nx)[nx==max(nx)]
```

Non ce n'est pas particulièrement surprenant car dans tout domaine il y a une ou plusieurs personnes qui travail un nombre d'heures aberrant.

Ce qui est plus surprenant c'est qu'il y aie une formation avec autant de différence, c'est à dire `Preschool` avec "seulement" 75h par semaine.

------------------------------------------------------------------------

### e) En s’inspirant des commandes utilisées ci-dessus, déterminer la formation pour laquelle la distribution des temps de travail se caractérise par le plus petit écart-type.

```{r}
MinSd<-by(dframe$hours_per_week, dframe$education, sd, na.rm=T)
MinSd
min(MinSd)
names(MinSd)[MinSd==min(MinSd)]
```

C'est donc la formation `Assoc-voc` qui a le plus petit écart-type avec 10.94331.

------------------------------------------------------------------------

### f) Observe-t-on un résultat similaire en utilisant l’étendue interquartiles à l’aide de la fonction IQR()?

```{r}
MinIqr<-by(dframe$hours_per_week, dframe$education, IQR, na.rm=T)
MinIqr
min(MinIqr)
names(MinIqr[MinIqr==min(MinIqr)])
```

Le résultat est maintenant différent car l'étendue interquartiles minimum est de 0 pour le type `5th-6th`.

------------------------------------------------------------------------

## Exercice 5

### Estimer et justifier les valeurs des coefficients de corrélation des séries de données à l’aide de leurs graphiques de nuage de points tracés dans la Figure 10, la Figure 11, la Figure 12 et la Figure 13.

#### Figure 10

Le coefficient de corrélation se trouve probablement entre 0.9 et 1. Il y a une forte corrélation car il n'y a pas de valeurs particulièrement extrêmes.

#### Figure 11

Cette fois le coefficient tend vers 0 car aucune corrélation n'est visible, les valeurs sont presque uniformément réparti sur toute l'espace de définition.

#### Figure 12

Le coefficient de corrélation n'est pas linéaire car les points se trouvent sur une forme hyperbolique

#### Figure 13

Cette figure représente presque une image miroir de la figure 10, son coefficient aura donc le même ordre de grandeur 0.9 à 1 mais cette fois il sera négatif. Ca donne donc une valeur probable entre -1 et -0.9 car plus x augmente, plus y diminue.

------------------------------------------------------------------------

## Exercice 6

### a) Utiliser les librairies skimr et summarytools pour afficher les sorties qui permettent d’effectuer une analyse exploratoire des données observées. Pour la librairie skimr appliquer la fonction tbl_summary() à l’objet iris; appliquer la fonction skim() à l’objet iris pour la librairie skimr.

```{r}
library(summarytools)
library(skimr)
library(gtsummary)
```

`tbl_summary` fait partie du package [gtsummary](https://www.danieldsjoberg.com/gtsummary/articles/tbl_summary.html).

```{r}
tbl_summary(iris)
```

```{r}
skim(iris)
```

```{r}
dfSummary(iris)
```

### b) La distribution de la largeur du sépale (Sepal.Width) est-elle plutôt symétrique ?
La distribution est en effet relativement symétrique. On voit ça grace aux graphes des fonctions `skim()` et `dfsummary()`. Pour un meilleur visuel on peut générer nous même le graphique.
```{r}
hist(iris$Sepal.Width, main = "Distribution de la largeur du sépale", xlab = "Sepal.Width", col = "lightblue")
```

### c) La distribution de la largeur du pétale (Petal.Width) est-elle unimodale ou bimodale ?
Tout comme pour la `Sepal.Width`, on peut générer nous même le graphique pour plus facilement l'analyser.
```{r}
hist(iris$Petal.Width, main = "Distribution de la largeur du pétale", xlab = "Petal.Width", col = "lightblue")
```
On voit ensuite que la distribution est bimodale avec un pic vers 0.1 cm et un deuxième vers 1.3 cm.

### d) Tracer le nuage de points de la largeur (Petal.Width) versus la longueur (Petal.Length) des pétales des iris en utilisant les librairies ggplot2 et ggforce.
```{r}
library(ggforce)

pCol <- c('#057076', '#ff8301', '#bf5ccb')

plot.iris<-ggplot(iris, aes(x=Petal.Length, y=Petal.Width, col=Species)) +
scale_color_manual(values=pCol) +
scale_x_continuous(breaks=seq(0.5, 7.5, by=1), limits=c(0.5, 7.5)) +
scale_y_continuous(breaks=seq(-0.5, 3, by=0.5), limits=c(-0.5, 3)) +
labs(title="Edgar Anderson's Iris Data",
x="Petal Length",
y="Petal Width") +
theme(plot.title=element_text(size=12, hjust=.5),
axis.title=element_text(size=10, vjust=-2),
axis.text=element_text(size=10, vjust=-2)) +
geom_point(aes(color=Species), alpha=.6, size=3) +
theme_minimal()

plot.iris +
ggforce::geom_mark_ellipse(
	aes(fill=Species, label=Species),
	alpha=.15, show.legend=FALSE
)
```

### e) En se basant sur le graphique de nuage de points, existe-t-il une relation entre la largeur et la longueur des pétales des iris ? Dans l’affirmative, de quelle nature est-elle ?
Oui, on voit bien qu'il y a une correlation entre les deux car les points suivent approximativement une droite de pente constante est positive.

Ceci veut donc dire qu'il y a un coefficient de correlation positif et approchant 1 entre la largeur et longueur de pétales des iris.

Plus les pétales sont large, plus elles sont longue.

### f) Remarque-t-on des observations inhabituelles dans le graphique de nuage de points ?
Non, il ne semble y avoir aucune valeur inhabituelle sur le graphique.

### g) Déterminer la corrélation entre la largeur et la longueur des pétales des iris en utilisant la fonction cor().
```{r}
cor(iris$Petal.Length, iris$Petal.Width)
```

### h) Quelle valeur attribueriez-vous à la longueur des pétales des iris pour distinguer les iris Setosa des deux autres espèces ?
Pour être large au niveau de l'estimation on peut attribuer les valeurs entre 0.5 et 2.5 car aucune pétale des deux autres espèces n'a été mesurée dans cette intervalle et elle englobe toutes les mesures des pétales de l'espèce Setosa.

### i) Des animations peuvent être créées dans R en utilisant la librairie gganimate. Un exemple peut être conçu en utilisant le code ci-dessous.
```{r}
library(gganimate)

anim<-plot.iris+
	transition_states(Species,
		transition_length = 2,
		state_length = 1)
anim

anim +
	enter_fade() +
	exit_shrink() +
	ggtitle('Now showing {closest_state}', subtitle = 'Frame {frame} of {nframes}')
```

------------------------------------------------------------------------

### j) (En option bonus) Installer la librairie reticulate qui permet de faire du Python à partir de RStudio IDE. Fixer ensuite l’interpréteur Python dans la rubrique Python de la boîte de dialogue Options. Cette boîte de dialogue s’affiche à l’écran en utilisant le menu Tools puis Global Options… de RStudio IDE.

```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

iris_py = r.iris

tab = {'setosa': 0, 'versicolor': 1, 'virginica': 2}

plt.figure(figsize=(10, 8))
plt.scatter(iris_py['Petal.Length'], iris_py['Petal.Width'], c=iris_py['Species'].map(tab), cmap='viridis')
plt.title("Iris Dataset")
plt.xlabel("petal length [cm]")
plt.ylabel("petal width [cm]")
plt.show()
```

------------------------------------------------------------------------

## Conclusion

Au cours de ce travail pratique nous avons découvert comment employer R ainsi que RStudio pour manipuler et comprendre des données. Par exemple nous les avons charger depuis des ressources externes, pour ensuite les modifier et les afficher. Ensuite nous avons pu les analyser et les représenter de diverses manières de sorte à mieux les comprendre.

Dans le but de rédiger ce rapport nous avons aussi pu apprendre à utiliser Quarto pour rendre du text, du code et des graphiques dans un format facile et agréable à lire.

------------------------------------------------------------------------
